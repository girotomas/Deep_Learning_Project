{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project 1: MNSIT Pair Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "# we imported pandas and IPython to display and better visualize the results\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the Models\n",
    "\n",
    "We define a class CNN that takes as a parameter the type of model to create. For example `CNN('deep')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Layer used to flatten the images\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return torch.reshape(x, (batch_size, -1))\n",
    "\n",
    "## Architectures: \n",
    "\n",
    "# The architecture represents the part of the model that recognizes the images.\n",
    "\n",
    "# Note: arch1, arch2, arch3 are functions that instanciate a new architecture not  architectures \n",
    "\n",
    "# Deep\n",
    "\n",
    "arch1 = lambda :  nn.Sequential(                    \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=35,           \n",
    "                kernel_size=3,             \n",
    "                stride=1,                   \n",
    "                padding=1,                 \n",
    "            ),                           \n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "            nn.Conv2d(35, 32, 5, 1, 4),   \n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                \n",
    "            Flatten(),        \n",
    "            nn.Linear(800,25),            \n",
    "            nn.Linear(25,25), \n",
    "            nn.Linear(25, 10) ,            \n",
    "            nn.BatchNorm1d(10),\n",
    "            nn.ReLU())\n",
    "\n",
    "\n",
    "# Fully connected\n",
    "\n",
    "arch2 = lambda  : nn.Sequential(                     \n",
    "            Flatten(),\n",
    "            nn.Linear(196, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 56),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(56, 10),              \n",
    "            nn.ReLU()\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "# Deep with sigmoids\n",
    "\n",
    "arch3 = lambda :  nn.Sequential(           \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=35,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=1,                 \n",
    "            ),                              \n",
    "            nn.Sigmoid(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),   \n",
    "            nn.Conv2d(35, 32, 5, 1, 4),  \n",
    "            nn.Sigmoid(),                      # activation\n",
    "            nn.MaxPool2d(2),              \n",
    "            Print('a'),\n",
    "            Flatten(),        \n",
    "            Print('b'),\n",
    "            nn.Linear(800,25),              # fully connected layer, output 25 classes\n",
    "            nn.Linear(25,25), \n",
    "            nn.Linear(25, 10) ,             # fully connected layer, output 10 classes\n",
    "            nn.BatchNorm1d(10),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    ''' To create this class use CNN(True, 'deep) for example.\n",
    "    other options are False, 'deep with sigmoids' and 'fully connected'. '''\n",
    " \n",
    "    def __init__(self, weight_sharing, architecture):\n",
    "        super(CNN, self).__init__()\n",
    "        self.weight_sharing = weight_sharing\n",
    "        self.architecture = architecture\n",
    "\n",
    "        # select the proper architecture\n",
    "        if architecture == 'deep':\n",
    "            # arch_copy is used with no weight sharing only\n",
    "            self.arch = arch1()\n",
    "            self.arch_copy = arch1()\n",
    "        if architecture == 'deep with sigmoids':\n",
    "            self.arch = arch3()\n",
    "            self.arch_copy = arch3()\n",
    "        if architecture == 'fully connected':\n",
    "            self.arch = arch2()\n",
    "            self.arch_copy = arch2()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 1) ,  \n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    # this function resets the weights to random\n",
    "    def reset(self):\n",
    "        self.__init__(self.weight_sharing, self.architecture)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #first convolutional layer\n",
    "\n",
    "\n",
    "        _x = torch.reshape(x[:,0,:,:], (-1, 1, 14, 14))\n",
    "        _x1 = self.arch(_x)\n",
    "        _x = torch.reshape(x[:,1,:,:], (-1, 1, 14, 14))\n",
    "\n",
    "        # if there is no weight sharing use the arch_copy layers\n",
    "        if self.weight_sharing: _x2 = self.arch(_x)\n",
    "        else: _x2 = self.arch_copy(_x)\n",
    "\n",
    "        #concatenate and retrun auxilary output\n",
    "        _x = torch.cat((_x1, _x2), 1)   \n",
    "        aux_out = (_x1, _x2)\n",
    "\n",
    "\n",
    "        #fc layer to merge the two recognitions\n",
    "        _x = self.fc(_x)\n",
    "        \n",
    "        # we print _x[:,0] because otherwise _x is of size (N,1) which is not usefull \n",
    "        # it should be of size (N)\n",
    "        return aux_out, _x[:,0]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With this function we compute the number of parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  We used the pandas library in order to better compare and plot the tables \n",
    "#  our test.py file doesn't use pandas so that it can run on the VM\n",
    "\n",
    "\n",
    "DATA=pd.DataFrame(columns = ['architecture', \n",
    "                             'training mode',\n",
    "                             'weight sharing', \n",
    "                             'history',\n",
    "                             'model', \n",
    "                            'loss function'])\n",
    "\n",
    "for architecture in ['deep', 'fully connected', 'deep with sigmoids']:\n",
    "    for weight_sharing in [True, False]:\n",
    "        for training_mode in ['without auxiliar loss', 'with auxiliar loss']:\n",
    "            \n",
    "            model = CNN(weight_sharing, architecture)\n",
    "            \n",
    "            if training_mode == 'without auxiliar loss':\n",
    "                loss_function = lambda loss_main, loss_aux: loss_main\n",
    "            elif training_mode == 'with auxiliar loss':\n",
    "                loss_function = lambda loss_main, loss_aux: loss_main + loss_aux\n",
    "            else:\n",
    "                raise Exception('wrong loss function')\n",
    "            \n",
    "            # history is an dictionary we created to store the values required to plot the graph\n",
    "            \n",
    "            DATA = DATA.append({'architecture':architecture,\n",
    "                               'training mode': training_mode,\n",
    "                               'weight sharing': weight_sharing,\n",
    "                               'history': pd.DataFrame(),\n",
    "                               'model':model,\n",
    "                               'loss function':loss_function,\n",
    "                               'number parameters': count_parameters(model)},\n",
    "                               ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>architecture</th>\n",
       "      <th>training mode</th>\n",
       "      <th>weight sharing</th>\n",
       "      <th>history</th>\n",
       "      <th>model</th>\n",
       "      <th>loss function</th>\n",
       "      <th>number parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deep</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>Empty DataFrame\n",
       "Columns: []\n",
       "Index: []</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f777ad0cae8&gt;</td>\n",
       "      <td>98697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deep</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>Empty DataFrame\n",
       "Columns: []\n",
       "Index: []</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f777acb2ae8&gt;</td>\n",
       "      <td>98697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deep</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>Empty DataFrame\n",
       "Columns: []\n",
       "Index: []</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f777accea60&gt;</td>\n",
       "      <td>98697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deep</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>Empty DataFrame\n",
       "Columns: []\n",
       "Index: []</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f777ac699d8&gt;</td>\n",
       "      <td>98697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>Empty DataFrame\n",
       "Columns: []\n",
       "Index: []</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Print()\\...</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f777ac82048&gt;</td>\n",
       "      <td>99067.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>Empty DataFrame\n",
       "Columns: []\n",
       "Index: []</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Print()\\...</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f777ac16510&gt;</td>\n",
       "      <td>99067.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>Empty DataFrame\n",
       "Columns: []\n",
       "Index: []</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Print()\\...</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f777ac2d9d8&gt;</td>\n",
       "      <td>99067.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>Empty DataFrame\n",
       "Columns: []\n",
       "Index: []</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Print()\\...</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f777ac42ea0&gt;</td>\n",
       "      <td>99067.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deep with sigmoids</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>Empty DataFrame\n",
       "Columns: []\n",
       "Index: []</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f777abdee18&gt;</td>\n",
       "      <td>98697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deep with sigmoids</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>Empty DataFrame\n",
       "Columns: []\n",
       "Index: []</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f777abfad90&gt;</td>\n",
       "      <td>98697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deep with sigmoids</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>Empty DataFrame\n",
       "Columns: []\n",
       "Index: []</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f777ab95d08&gt;</td>\n",
       "      <td>98697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>deep with sigmoids</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>Empty DataFrame\n",
       "Columns: []\n",
       "Index: []</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7f777abb0c80&gt;</td>\n",
       "      <td>98697.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          architecture          training mode weight sharing  \\\n",
       "0                 deep  without auxiliar loss           True   \n",
       "1                 deep     with auxiliar loss           True   \n",
       "2                 deep  without auxiliar loss          False   \n",
       "3                 deep     with auxiliar loss          False   \n",
       "4      fully connected  without auxiliar loss           True   \n",
       "5      fully connected     with auxiliar loss           True   \n",
       "6      fully connected  without auxiliar loss          False   \n",
       "7      fully connected     with auxiliar loss          False   \n",
       "8   deep with sigmoids  without auxiliar loss           True   \n",
       "9   deep with sigmoids     with auxiliar loss           True   \n",
       "10  deep with sigmoids  without auxiliar loss          False   \n",
       "11  deep with sigmoids     with auxiliar loss          False   \n",
       "\n",
       "                                  history  \\\n",
       "0   Empty DataFrame\n",
       "Columns: []\n",
       "Index: []   \n",
       "1   Empty DataFrame\n",
       "Columns: []\n",
       "Index: []   \n",
       "2   Empty DataFrame\n",
       "Columns: []\n",
       "Index: []   \n",
       "3   Empty DataFrame\n",
       "Columns: []\n",
       "Index: []   \n",
       "4   Empty DataFrame\n",
       "Columns: []\n",
       "Index: []   \n",
       "5   Empty DataFrame\n",
       "Columns: []\n",
       "Index: []   \n",
       "6   Empty DataFrame\n",
       "Columns: []\n",
       "Index: []   \n",
       "7   Empty DataFrame\n",
       "Columns: []\n",
       "Index: []   \n",
       "8   Empty DataFrame\n",
       "Columns: []\n",
       "Index: []   \n",
       "9   Empty DataFrame\n",
       "Columns: []\n",
       "Index: []   \n",
       "10  Empty DataFrame\n",
       "Columns: []\n",
       "Index: []   \n",
       "11  Empty DataFrame\n",
       "Columns: []\n",
       "Index: []   \n",
       "\n",
       "                                                model  \\\n",
       "0   CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...   \n",
       "1   CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...   \n",
       "2   CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...   \n",
       "3   CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...   \n",
       "4   CNN(\\n  (arch): Sequential(\\n    (0): Print()\\...   \n",
       "5   CNN(\\n  (arch): Sequential(\\n    (0): Print()\\...   \n",
       "6   CNN(\\n  (arch): Sequential(\\n    (0): Print()\\...   \n",
       "7   CNN(\\n  (arch): Sequential(\\n    (0): Print()\\...   \n",
       "8   CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...   \n",
       "9   CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...   \n",
       "10  CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...   \n",
       "11  CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...   \n",
       "\n",
       "                            loss function  number parameters  \n",
       "0   <function <lambda> at 0x7f777ad0cae8>            98697.0  \n",
       "1   <function <lambda> at 0x7f777acb2ae8>            98697.0  \n",
       "2   <function <lambda> at 0x7f777accea60>            98697.0  \n",
       "3   <function <lambda> at 0x7f777ac699d8>            98697.0  \n",
       "4   <function <lambda> at 0x7f777ac82048>            99067.0  \n",
       "5   <function <lambda> at 0x7f777ac16510>            99067.0  \n",
       "6   <function <lambda> at 0x7f777ac2d9d8>            99067.0  \n",
       "7   <function <lambda> at 0x7f777ac42ea0>            99067.0  \n",
       "8   <function <lambda> at 0x7f777abdee18>            98697.0  \n",
       "9   <function <lambda> at 0x7f777abfad90>            98697.0  \n",
       "10  <function <lambda> at 0x7f777ab95d08>            98697.0  \n",
       "11  <function <lambda> at 0x7f777abb0c80>            98697.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this table contains all the models, all the training history's of the models and the loss functions\n",
    "# the history objects contain the data to make visualize the training curves. Those curves can be \n",
    "# visualized in our test.py file\n",
    "\n",
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to compute classes accuracy of the digit recognition\n",
    "# it allows to plot the accuracy function of the digit recognition (this was not mandatory but \n",
    "# it helps to visualize how the training is done)\n",
    "\n",
    "def accuracy_classes(predicted, target):\n",
    "    '''\n",
    "    computes the accuracy of the predicted classes in %\n",
    "    '''\n",
    "\n",
    "    predicted_1 = predicted[0]\n",
    "    predicted_2 = predicted[1]\n",
    "    predicted_1 = predicted_1.argmax(dim=1)\n",
    "    predicted_2 = predicted_2.argmax(dim=1)\n",
    "    target_1=target[:,0]\n",
    "    target_2=target[:,1]\n",
    "    return ( 100 -( ( (target_1 != predicted_1) | (target_2 != predicted_2 ) ).sum() ).item() /target_1.shape[0] * 100 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function calculated the accuracy for the output\n",
    "def accuracy_comparison(predicted, target):\n",
    "    '''computes accuracy for the output'''\n",
    "    return( np.array((torch.abs(predicted - target) < 0.5).sum().float() / target.shape[0] * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# d is a history  containing the info of the training\n",
    "# this function plots the graphs of the learning curves\n",
    "def plot_graphs(data_row, d):\n",
    "    # plotting accuracy\n",
    "    plt.figure(figsize=(10,6))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "\n",
    "\n",
    "    description =  'model of type '+data_row['architecture']+',\\n with lr= '+str(d['learning rate'])+\\\n",
    "    (', with weight sharing, ' if data_row['weight sharing'] else ', without weight sharing, ') +\\\n",
    "        'and loss function '+ data_row['training mode'] \n",
    "\n",
    "    plt.suptitle('Learning curves of the '+ description)\n",
    "\n",
    "    plt.plot(d['comparison acc'], label='comparison acc')\n",
    "    if data_row['training mode']== 'with auxiliar loss': plt.plot(d['recognition acc'], label='recognition acc')\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy  in %')\n",
    "    plt.ylim((0,100))\n",
    "\n",
    "    # plotting loss\n",
    "    plt.subplot(1,2,2)\n",
    "\n",
    "\n",
    "\n",
    "    plt.plot(d['comparison loss'], label='comparison loss')\n",
    "    if data_row['training mode']== 'with auxiliar loss': plt.plot(d['recognition loss'], label='recognition loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.ylim((0,2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_number(i):\n",
    "'''This function is used to train a model, save the results in the DATA\n",
    "table and plot the results of the training, the input is the number of the model.\n",
    "The number of the model is the index of the row of the dataframe DATA'''\n",
    "    data_row = DATA.iloc[i]\n",
    "    display(data_row)\n",
    "    display(Markdown('''### Model:\n",
    "     - '''+data_row['architecture']+'''\n",
    "     - '''+data_row['training mode']+'''\n",
    "     - '''+('with weight sharing' if data_row['weight sharing'] else 'without weight sharing')+'''\n",
    "    '''))\n",
    "    model = data_row['model']\n",
    "    model.reset()\n",
    "    loss_function = data_row['loss function']\n",
    "    architecture = data_row['architecture']\n",
    "\n",
    "\n",
    "    \n",
    "    # Training of the model\n",
    "    if architecture == 'fully connected': eta = 0.01\n",
    "    if architecture == 'deep with sigmoids': eta = 0.01\n",
    "    if architecture == 'deep': eta = 0.2\n",
    "    mini_batch_size = 100\n",
    "    epochs = 30\n",
    "\n",
    "    # dictionnary to store the values a.k.a history\n",
    "    d= ({'epochs': epochs,\n",
    "                'comparison loss':[],\n",
    "               'recognition loss':[],\n",
    "               'comparison acc':[],\n",
    "               'recognition acc':[],\n",
    "               'learning rate':eta})\n",
    "    \n",
    "    \n",
    "    criterion_aux = nn.CrossEntropyLoss() # criterion for digit recognition\n",
    "    criterion_main = torch.nn.BCELoss() # criterion for digit comparison\n",
    "\n",
    "    # use adam optimizer for SGD\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=eta)\n",
    "\n",
    "    # compute minibatch test target\n",
    "    minibatch_test_target = test_target.narrow(0, 0, mini_batch_size)\n",
    "    minibatch_test_input = test_input.narrow(0, 0, mini_batch_size)\n",
    "\n",
    "\n",
    "    # print total number of epochs\n",
    "    print('epoch: (../ '+str(epochs-1)+' )')\n",
    "\n",
    "    # necessary for loss_function\n",
    "    aux_validation_acc_item = 0\n",
    "\n",
    "    for e in range(0, epochs):\n",
    "        #print current epoch\n",
    "        print(str(e), sep=' ', end=' ', flush=True)\n",
    "        \n",
    "        if e in [epochs//2, epochs//3, epochs//4]: eta /=2\n",
    "        \n",
    "\n",
    "        # We do this with mini-batches\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "\n",
    "            mini_batch_input = train_input.narrow(0, b, mini_batch_size)\n",
    "            mini_batch_target = train_target.narrow(0, b, mini_batch_size) #classification labels Nx1\n",
    "            mini_batch_target_aux = train_classes.narrow(0, b, mini_batch_size) #binary 'what number are these images' Nx20\n",
    "\n",
    "\n",
    "            #output_aux is the Nx20 output of the second fc layer corresponding to what image pairs were predicted\n",
    "            #output is the Nx1 output corresponding to: if image 0 or image 1 is bigger\n",
    "            output_aux, output = model(mini_batch_input)  \n",
    "            loss_aux = criterion_aux(output_aux[0], mini_batch_target_aux[:,0]) +\\\n",
    "            criterion_aux(output_aux[1], mini_batch_target_aux[:,1])\n",
    "            loss_main = criterion_main(output, mini_batch_target.float())\n",
    "            \n",
    "            # we get the values of the losses at time 0\n",
    "            if b==0 and e==0: loss_main0, loss_aux0 = loss_main.data.item(), loss_aux.data.item()\n",
    "            \n",
    "            # we normalize the losses \n",
    "            loss_main/=loss_main0\n",
    "            loss_aux/=loss_aux0\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        # compute validation loss and accuracy\n",
    "            if b ==0:\n",
    "                with torch.no_grad():\n",
    "\n",
    "\n",
    "                    #compute outputs for test data\n",
    "                    validation_output_aux, validation_output = model(test_input)\n",
    "\n",
    "                    # compute loss for test data\n",
    "                    main_validation_loss = criterion_main( validation_output, test_target.float()) /loss_main0\n",
    "                    aux_validation_loss = criterion_aux( validation_output_aux[0], test_classes[:,0].long()) / loss_aux0 + criterion_aux(validation_output_aux[1], test_classes[:,1].long()) / loss_aux0\n",
    "\n",
    "                    # compute accuracy for test and train data\n",
    "                    main_validation_acc_item = accuracy_comparison( validation_output, test_target.float())\n",
    "                    aux_validation_acc_item = accuracy_classes(validation_output_aux, test_classes)\n",
    "\n",
    "\n",
    "                    # append to arrays\n",
    "                # save results in d\n",
    "\n",
    "\n",
    "                d['comparison loss'].append(main_validation_loss.item())\n",
    "                d['recognition loss'].append(aux_validation_loss.item())\n",
    "                d['comparison acc'].append(main_validation_acc_item)\n",
    "                d['recognition acc'].append(aux_validation_acc_item)\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_function( loss_main, loss_aux )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            \n",
    "    history_of_historys = DATA.iloc[i,3]\n",
    "    history_of_historys = history_of_historys.append(d, ignore_index = True)\n",
    "    DATA.at[i,'history'] = history_of_historys\n",
    "\n",
    "\n",
    "    plot_graphs(data_row, d )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We used this code to compute all the data.\n",
    "\n",
    "for j in range(10):\n",
    "    # When we reimport the data the images are randomized as requested\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(1000)\n",
    "    for i in range(len(DATA)):\n",
    "            run_number(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We used this code to save the data in a file DATA2\n",
    "#DATA.iloc[:,range(4)].to_pickle('./DATA2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this code reloads the saved data\n",
    "DATA = pd.read_pickle('./DATA2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA2 is a new dataframe containing only the columns usefull for the visualization\n",
    "\n",
    "DATA2=DATA.loc[:,['architecture', 'training mode', 'weight sharing']]\n",
    "\n",
    "# here we compute the mean and the std of the training results. This allows us to \n",
    "# interpret them.\n",
    "DATA2['mean comparison acc'] = [np.array([ np.array(comparison_acc).max()  for comparison_acc in history['comparison acc'] ]).mean() for history in  DATA['history']]\n",
    "DATA2['std comparison acc'] = [np.array([ np.array(comparison_acc).max()  for comparison_acc in history['comparison acc'] ]).std() for history in  DATA['history']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Mean and std by architecture"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean comparison acc</th>\n",
       "      <th>std comparison acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>architecture</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deep</th>\n",
       "      <td>80.197504</td>\n",
       "      <td>0.925939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep with sigmoids</th>\n",
       "      <td>76.534317</td>\n",
       "      <td>0.856359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fully connected</th>\n",
       "      <td>73.787498</td>\n",
       "      <td>4.430183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean comparison acc  std comparison acc\n",
       "architecture                                               \n",
       "deep                          80.197504            0.925939\n",
       "deep with sigmoids            76.534317            0.856359\n",
       "fully connected               73.787498            4.430183"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Ranking of all models"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>architecture</th>\n",
       "      <th>training mode</th>\n",
       "      <th>weight sharing</th>\n",
       "      <th>mean comparison acc</th>\n",
       "      <th>std comparison acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deep</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>81.910004</td>\n",
       "      <td>1.208679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deep</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>80.620010</td>\n",
       "      <td>0.442268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deep</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>79.430008</td>\n",
       "      <td>1.337198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deep</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>78.829994</td>\n",
       "      <td>0.715610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deep with sigmoids</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>78.027275</td>\n",
       "      <td>0.598619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>76.709999</td>\n",
       "      <td>1.060612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deep with sigmoids</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>76.639999</td>\n",
       "      <td>1.078146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>deep with sigmoids</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>75.909996</td>\n",
       "      <td>0.703492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deep with sigmoids</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>75.559998</td>\n",
       "      <td>1.045181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>74.579994</td>\n",
       "      <td>0.491528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>73.550003</td>\n",
       "      <td>3.769684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>70.309998</td>\n",
       "      <td>12.398907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          architecture          training mode weight sharing  \\\n",
       "1                 deep     with auxiliar loss           True   \n",
       "0                 deep  without auxiliar loss           True   \n",
       "3                 deep     with auxiliar loss          False   \n",
       "2                 deep  without auxiliar loss          False   \n",
       "9   deep with sigmoids     with auxiliar loss           True   \n",
       "4      fully connected  without auxiliar loss           True   \n",
       "8   deep with sigmoids  without auxiliar loss           True   \n",
       "11  deep with sigmoids     with auxiliar loss          False   \n",
       "10  deep with sigmoids  without auxiliar loss          False   \n",
       "6      fully connected  without auxiliar loss          False   \n",
       "7      fully connected     with auxiliar loss          False   \n",
       "5      fully connected     with auxiliar loss           True   \n",
       "\n",
       "    mean comparison acc  std comparison acc  \n",
       "1             81.910004            1.208679  \n",
       "0             80.620010            0.442268  \n",
       "3             79.430008            1.337198  \n",
       "2             78.829994            0.715610  \n",
       "9             78.027275            0.598619  \n",
       "4             76.709999            1.060612  \n",
       "8             76.639999            1.078146  \n",
       "11            75.909996            0.703492  \n",
       "10            75.559998            1.045181  \n",
       "6             74.579994            0.491528  \n",
       "7             73.550003            3.769684  \n",
       "5             70.309998           12.398907  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Weight sharing vs. no weight sharing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean comparison acc</th>\n",
       "      <th>std comparison acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight sharing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>77.369548</td>\n",
       "      <td>2.797872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>76.309999</td>\n",
       "      <td>1.343782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean comparison acc  std comparison acc\n",
       "weight sharing                                         \n",
       "True                      77.369548            2.797872\n",
       "False                     76.309999            1.343782"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Auxiliary loss vs. normal loss with convolutional arch."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean comparison acc</th>\n",
       "      <th>std comparison acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training mode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>with auxiliar loss</th>\n",
       "      <td>78.819321</td>\n",
       "      <td>0.961997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>without auxiliar loss</th>\n",
       "      <td>77.912500</td>\n",
       "      <td>0.820301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean comparison acc  std comparison acc\n",
       "training mode                                                 \n",
       "with auxiliar loss               78.819321            0.961997\n",
       "without auxiliar loss            77.912500            0.820301"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Before tricks"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>architecture</th>\n",
       "      <th>training mode</th>\n",
       "      <th>weight sharing</th>\n",
       "      <th>mean comparison acc</th>\n",
       "      <th>std comparison acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deep</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>78.829994</td>\n",
       "      <td>0.715610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deep with sigmoids</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>75.559998</td>\n",
       "      <td>1.045181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>74.579994</td>\n",
       "      <td>0.491528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          architecture          training mode weight sharing  \\\n",
       "2                 deep  without auxiliar loss          False   \n",
       "10  deep with sigmoids  without auxiliar loss          False   \n",
       "6      fully connected  without auxiliar loss          False   \n",
       "\n",
       "    mean comparison acc  std comparison acc  \n",
       "2             78.829994            0.715610  \n",
       "10            75.559998            1.045181  \n",
       "6             74.579994            0.491528  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With this code we display the following tables.\n",
    "display(Markdown('### Mean and std by architecture'))\n",
    "display(DATA2.groupby('architecture').mean().sort_values('mean comparison acc', ascending = False))\n",
    "\n",
    "display(Markdown('### Ranking of all models'))\n",
    "display(DATA2.sort_values('mean comparison acc', ascending = False))\n",
    "\n",
    "display(Markdown('### Weight sharing vs. no weight sharing'))\n",
    "display(DATA2.groupby('weight sharing').mean().sort_values('mean comparison acc', ascending = False))\n",
    "\n",
    "\n",
    "display(Markdown('### Auxiliary loss vs. normal loss with convolutional arch.'))\n",
    "display(DATA2[DATA2['architecture']!='fully connected'].groupby('training mode').mean().sort_values('mean comparison acc', ascending = False))\n",
    "\n",
    "\n",
    "display(Markdown('### Before tricks'))\n",
    "\n",
    "DATA2[(DATA2['training mode']=='without auxiliar loss') & (DATA2['weight sharing']==False)].sort_values('mean comparison acc', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
