{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project 1: MNSIT Pair Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import dlc_practical_prologue as prologue\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class Print(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "#method to flatten the images\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return torch.reshape(x, (batch_size, -1))\n",
    "## Architectures: \n",
    "\n",
    "# The architecture represents the part of the model that recognizes the images.\n",
    "\n",
    "# Deep\n",
    "\n",
    "# Note: arch1,arch2,arch3 are functions that instanciate a new architecture not  architectures !\n",
    "arch1 = lambda :  nn.Sequential(                     # input shape (100, 2, 14, 14)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=1,                  # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 7, 7)\n",
    "            nn.Dropout2d(0.05),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 32, 5, 1, 4),     # output shape (32, 7, 7)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "            nn.Dropout2d(0.05),\n",
    "            nn.BatchNorm2d(32),\n",
    "            Flatten(),        \n",
    "            nn.Linear(800,20),      # fully connected layer, output 10 classes\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(20, 10) ,             # fully connected layer, output 10 classes\n",
    "            nn.BatchNorm1d(10),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.ReLU())\n",
    "\n",
    "\n",
    "# Fully connected\n",
    "\n",
    "arch2 = lambda  : nn.Sequential(                      # input shape (1, 28, 28)\n",
    "            Flatten(),\n",
    "            nn.Linear(56, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 56),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(56, 10),              \n",
    "            nn.ReLU()\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "# Deep with sigmoids\n",
    "\n",
    "arch3 =  lambda  :  nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=2,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=4,                  # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.Sigmoid(),                   # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "            nn.Dropout2d(0.05),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 32, 5, 1, 4),     # output shape (32, 14, 14)\n",
    "            nn.Sigmoid(),                   # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "            nn.Dropout2d(0.05),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Linear(32 * 7 * 7, 20),      # fully connected layer, output 10 classes\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(20, 10) ,             # fully connected layer, output 10 classes\n",
    "            nn.BatchNorm1d(10),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.ReLU())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    ''' To create this class use CNN(True, 'deep) for example.\n",
    "    other options are False, 'deep with sigmoids' and 'fully connected'. '''\n",
    " \n",
    "    def __init__(self, weight_sharing, architecture):\n",
    "        super(CNN, self).__init__()\n",
    "        self.weight_sharing = weight_sharing\n",
    "\n",
    "        # select the proper architecture\n",
    "        if architecture == 'deep':\n",
    "            # arch_copy is used with no weight sharing only\n",
    "            self.arch = arch1()\n",
    "            self.arch_copy = arch1()\n",
    "        if architecture == 'deep with sigmoids':\n",
    "            self.arch = arch3()\n",
    "            self.arch_copy = arch3()\n",
    "        if architecture == 'fully connected':\n",
    "            self.arch = arch2()\n",
    "            self.arch_copy = arch2()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 1) ,  # fully connected layer, output 10 classes\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #first convolutional layer\n",
    "\n",
    "\n",
    "        _x = torch.reshape(x[:,0,:,:], (-1, 1, 14, 14))\n",
    "        _x1 = self.arch(_x)\n",
    "        _x = torch.reshape(x[:,1,:,:], (-1, 1, 14, 14))\n",
    "\n",
    "        # if there is no weight sharing use the arch_copy layers\n",
    "        if self.weight_sharing: _x2 = self.arch(_x)\n",
    "        else: _x2 = self.arch_copy(_x)\n",
    "\n",
    "        #concatenate and retrun auxilary output\n",
    "        _x = torch.cat((_x1, _x2), 1)   \n",
    "        aux_out = (_x1, _x2)\n",
    "\n",
    "\n",
    "        #fc layer to merge the two recognitions\n",
    "        _x = self.fc(_x)\n",
    "        \n",
    "        # we print _x[:,0] because otherwise _x is of size (N,1) which is not usefull \n",
    "        # it should be of size (N)\n",
    "        return aux_out, _x[:,0]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA=pd.DataFrame(columns = ['architecture', \n",
    "                             'training mode',\n",
    "                             'weight sharing', \n",
    "                             'accuracy',\n",
    "                             'digit recognition accuracy',\n",
    "                             'model'])\n",
    "\n",
    "for architecture in ['deep', 'fully connected', 'deep with sigmoids']:\n",
    "    for weight_sharing in [True, False]:\n",
    "        for training_mode in ['without auxiliar loss', 'with auxiliar loss']:\n",
    "            \n",
    "            model = CNN(weight_sharing, architecture)\n",
    "            \n",
    "            DATA = DATA.append({'architecture':architecture,\n",
    "                               'training mode': training_mode,\n",
    "                               'weight sharing': weight_sharing,\n",
    "                               'accuracy': [],\n",
    "                               'digit recognition accuracy':[],\n",
    "                               'model':model},\n",
    "                               ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>architecture</th>\n",
       "      <th>training mode</th>\n",
       "      <th>weight sharing</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>digit recognition accuracy</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deep</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deep</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deep</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deep</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Flatten(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Flatten(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Flatten(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Flatten(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deep with sigmoids</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deep with sigmoids</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deep with sigmoids</td>\n",
       "      <td>without auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>deep with sigmoids</td>\n",
       "      <td>with auxiliar loss</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          architecture          training mode weight sharing accuracy  \\\n",
       "0                 deep  without auxiliar loss           True       []   \n",
       "1                 deep     with auxiliar loss           True       []   \n",
       "2                 deep  without auxiliar loss          False       []   \n",
       "3                 deep     with auxiliar loss          False       []   \n",
       "4      fully connected  without auxiliar loss           True       []   \n",
       "5      fully connected     with auxiliar loss           True       []   \n",
       "6      fully connected  without auxiliar loss          False       []   \n",
       "7      fully connected     with auxiliar loss          False       []   \n",
       "8   deep with sigmoids  without auxiliar loss           True       []   \n",
       "9   deep with sigmoids     with auxiliar loss           True       []   \n",
       "10  deep with sigmoids  without auxiliar loss          False       []   \n",
       "11  deep with sigmoids     with auxiliar loss          False       []   \n",
       "\n",
       "   digit recognition accuracy  \\\n",
       "0                          []   \n",
       "1                          []   \n",
       "2                          []   \n",
       "3                          []   \n",
       "4                          []   \n",
       "5                          []   \n",
       "6                          []   \n",
       "7                          []   \n",
       "8                          []   \n",
       "9                          []   \n",
       "10                         []   \n",
       "11                         []   \n",
       "\n",
       "                                                model  \n",
       "0   CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...  \n",
       "1   CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...  \n",
       "2   CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...  \n",
       "3   CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...  \n",
       "4   CNN(\\n  (arch): Sequential(\\n    (0): Flatten(...  \n",
       "5   CNN(\\n  (arch): Sequential(\\n    (0): Flatten(...  \n",
       "6   CNN(\\n  (arch): Sequential(\\n    (0): Flatten(...  \n",
       "7   CNN(\\n  (arch): Sequential(\\n    (0): Flatten(...  \n",
       "8   CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...  \n",
       "9   CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...  \n",
       "10  CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...  \n",
       "11  CNN(\\n  (arch): Sequential(\\n    (0): Conv2d(1...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-c270ddba4145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# un hot-encode train and test classes to use the function nn.CrossEntropyLoss()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(self, dim, keepdim)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;34mr\"\"\"See :func:`torch.argmax`\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(input, dim, keepdim)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_argmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_argmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "# un hot-encode train and test classes to use the function nn.CrossEntropyLoss() \n",
    "train_classes = train_classes.argmax(dim = 2)\n",
    "test_classes = test_classes.argmax(dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 2],\n",
       "        [0, 2],\n",
       "        [7, 9],\n",
       "        ...,\n",
       "        [9, 3],\n",
       "        [4, 0],\n",
       "        [7, 9]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train and test classes to categorical\n",
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return torch.Tensor(np.eye(num_classes, dtype='uint8')[y]).type(torch.LongTensor)\n",
    "train_classes, test_classes = to_categorical(train_classes, 10), to_categorical(test_classes, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to compute classes accuracy\n",
    "def accuracy_classes(predicted, target):\n",
    "    '''\n",
    "    computes the accuracy of the predicted classes in %\n",
    "    '''\n",
    "\n",
    "    predicted_1 = predicted[0]\n",
    "    predicted_2 = predicted[1]\n",
    "    predicted_1 = predicted_1.argmax(dim=1)\n",
    "    predicted_2 = predicted_2.argmax(dim=1)\n",
    "    target_1=target[:,0]\n",
    "    target_2=target[:,1]\n",
    "    return ( 100 -( ( (target_1 != predicted_1) | (target_2 != predicted_2 ) ).sum() ).item() /target_1.shape[0] * 100 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_comparison(predicted, target):\n",
    "    '''computes accuracy for output'''\n",
    "    return( (torch.abs(predicted - target) < 0.5).sum().float() / target.shape[0] * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: (../ 5 )\n",
      "0 "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [22400 x 7], m2: [1568 x 20] at /opt/conda/conda-bld/pytorch_1549628766161/work/aten/src/TH/generic/THTensorMath.cpp:940",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-f08d3683a18b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m#output_aux is the Nx20 output of the second fc layer corresponding to what image pairs were predicted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m#output is the Nx1 output corresponding to: if image 0 or image 1 is bigger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0moutput_aux\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mloss_aux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_aux\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_aux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_target_aux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m        \u001b[0mcriterion_aux\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_aux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_target_aux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mloss_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-4dfbda722e02>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0m_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0m_x1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0m_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [22400 x 7], m2: [1568 x 20] at /opt/conda/conda-bld/pytorch_1549628766161/work/aten/src/TH/generic/THTensorMath.cpp:940"
     ]
    }
   ],
   "source": [
    "loss_function = lambda x, y : x+y\n",
    "\n",
    "data_row = DATA.iloc[0]\n",
    "\n",
    "# dictionnary to store the values\n",
    "d= {'comparison loss':[],\n",
    "           'recognition loss':[],\n",
    "           'comparison acc':[],\n",
    "           'recognition acc':[]}\n",
    "\n",
    "\n",
    "# Training of the model\n",
    "eta= 0.0001\n",
    "mini_batch_size = 100\n",
    "epochs = 5\n",
    "\n",
    "criterion_aux = nn.CrossEntropyLoss() # criterion for digit recognition\n",
    "criterion_main = torch.nn.BCELoss() # criterion for digit comparison\n",
    "\n",
    "# use adam optimizer for SGD\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=eta)\n",
    "\n",
    "# compute minibatch test target\n",
    "minibatch_test_target = test_target.narrow(0, 0, mini_batch_size)\n",
    "minibatch_test_input = test_input.narrow(0, 0, mini_batch_size)\n",
    "\n",
    "\n",
    "# print total number of epochs\n",
    "print('epoch: (../ '+str(epochs)+' )')\n",
    "\n",
    "# necessary for loss_function\n",
    "aux_validation_acc_item = 0\n",
    "\n",
    "for e in range(0, epochs):\n",
    "    #print current epoch\n",
    "    print(str(e), sep=' ', end=' ', flush=True)\n",
    "\n",
    "    # We do this with mini-batches\n",
    "    for b in range(0, train_input.size(0), mini_batch_size):\n",
    "\n",
    "        mini_batch_input = train_input.narrow(0, b, mini_batch_size)\n",
    "        mini_batch_target = train_target.narrow(0, b, mini_batch_size) #classification labels Nx1\n",
    "        mini_batch_target_aux = train_classes.narrow(0, b, mini_batch_size) #binary 'what number are these images' Nx20\n",
    "\n",
    "\n",
    "        #output_aux is the Nx20 output of the second fc layer corresponding to what image pairs were predicted\n",
    "        #output is the Nx1 output corresponding to: if image 0 or image 1 is bigger\n",
    "        output_aux, output = model(mini_batch_input)  \n",
    "        loss_aux = criterion_aux(output_aux[0], mini_batch_target_aux[:,0]) +\\\n",
    "        criterion_aux(output_aux[1], mini_batch_target_aux[:,1])\n",
    "        loss_main = criterion_main(output, mini_batch_target.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function( loss_main, loss_aux )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    # compute validation loss and accuracy\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "\n",
    "        #compute outputs for test data\n",
    "        validation_output_aux, validation_output = model(test_input)\n",
    "\n",
    "        # compute loss for test data\n",
    "        main_validation_loss = criterion_main( validation_output, test_target.float()) \n",
    "        aux_validation_loss = criterion_aux( validation_output_aux[0], test_classes[:,0].long()) + criterion_aux(validation_output_aux[1], test_classes[:,0].long())\n",
    "\n",
    "        # compute accuracy for test and train data\n",
    "        main_validation_acc_item = accuracy_comparison( validation_output, test_target.float())\n",
    "        aux_validation_acc_item = accuracy_classes(validation_output_aux, test_classes)\n",
    "\n",
    "\n",
    "        # append to arrays\n",
    "        # save results in d\n",
    "      \n",
    "\n",
    "        d['comparison loss'].append(main_validation_loss.item())\n",
    "        d['recognition loss'].append(aux_validation_loss.item())\n",
    "        d['comparison acc'].append(main_validation_acc_item)\n",
    "        d['recognition acc'].append(aux_validation_acc_item)\n",
    "\n",
    "display(Markdown('''### Model:\n",
    " - '''+data_row['architecture']+'''\n",
    " - '''+data_row['training mode']+'''\n",
    " - '''+('with weight sharing' if data_row['weight sharing'] else 'without weight sharing')+'''\n",
    "'''))\n",
    "\n",
    "\n",
    "        \n",
    "# plotting accuracy\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "\n",
    "description =  'model of type '+data_row['architecture']+',\\n with lr= '+str(eta)+\\\n",
    "(', with weight sharing, ' if data_row['weight sharing'] else ', without weight sharing, ') +\\\n",
    "    'and loss function '+ data_row['training mode'] \n",
    "\n",
    "plt.title('Accuracy curves of the '+ description)\n",
    "\n",
    "plt.plot(d['comparison acc'], label='comparison acc')\n",
    "plt.plot(d['recognition acc'], label='recognition acc')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy  in %')\n",
    "plt.show()\n",
    "\n",
    "# plotting loss\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "plt.title('Loss curves of the '+description)\n",
    "\n",
    "\n",
    "plt.plot(d['comparison loss'], label='comparison loss')\n",
    "plt.plot(d['recognition loss'], label='recognition loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
